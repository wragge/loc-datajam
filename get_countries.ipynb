{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d0020db-a581-47b9-ae01-f2578773d48e",
   "metadata": {},
   "source": [
    "# Look for countries in Wikidata matching the place names extracted through NER\n",
    "\n",
    "This notebook feeds the place names extracted from the books via NER to Wikidata to see if there's a country by that name. It searches the main label field as well as alternative labels, and accepts entities that are instances of `country`, `historical country`, or `sovereign state`.\n",
    "\n",
    "The original place name, the matched country name, the instance type, and Wikidata links are saved to an `ndjson` file (one JSON object per line). Dates and geocordinates are included if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "077479a6-36b3-4a6f-a89b-28e4ff30cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import JSON, SPARQLWrapper\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2394312c-d980-45f9-9a37-a2a04c12f24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\", agent=\"GLAMWorkbench notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd49870b-07ec-4397-a849-0d98e5634e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_clean(results, is_int=[]):\n",
    "    \"\"\"\n",
    "    Convert SPARQL query results into a Pandas Dataframe.\n",
    "    Flatten the nested structures and remove the datatype info to leave only the fields and values.\n",
    "    Convert string ints to ints.\n",
    "    \"\"\"\n",
    "    # Use json_normalize to import and flatten the JSON\n",
    "    df = pd.json_normalize(results[\"results\"][\"bindings\"], sep=\"_\")\n",
    "    # Drop columns that don't have 'value' in their name\n",
    "    columns = [c for c in df.columns if c.endswith(\"_value\")]\n",
    "    df = df[columns]\n",
    "    # Rename columns to remove '_value'\n",
    "    df.rename(lambda x: re.sub(r\"_value$\", \"\", x), axis=1, inplace=True)\n",
    "    # Make sure columns containing integers have an integer data type.\n",
    "    for int_col in is_int:\n",
    "        df[int_col] = df[int_col].astype(\"Int64\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bad9404-dfdc-42dc-85f1-c429ee1c63aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Scotland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>New Jersey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Aberdeen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Joannes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0            1\n",
       "0  3     Scotland\n",
       "1  3   New Jersey\n",
       "2  3  Los Angeles\n",
       "3  3     Aberdeen\n",
       "4  3      Joannes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the placenames data file\n",
    "df = pd.read_csv(\"spacy_ner.txt\", delimiter=\"\\t\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275ee931-fdce-4475-a505-5b52d582affc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4170275, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of place names\n",
    "ents = df[1].to_frame()\n",
    "ents.columns = ['label']\n",
    "ents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9adbfa83-d6d8-4c2e-8fb8-1913203b28e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1060910, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deduplicate the place names\n",
    "ents.drop_duplicates(inplace=True)\n",
    "ents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ce4505-85d7-4e17-9ecd-e1f4653b3815",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template = \"\"\"\n",
    "SELECT ?text ?country ?countryLabel ?countryTypeLabel ?startDate ?endDate ?lat ?lon WHERE {{\n",
    "  # Get country, historical country, or soverign state -- historical country is a subclass of country but is not preferred, so can't get it with P31/P279*\n",
    "  VALUES ?class {{wd:Q6256 wd:Q3024240 wd:Q3624078}}.\n",
    "  # This will get populated with a batch of placenames\n",
    "  VALUES ?text {{{}}}\n",
    "  # Match either label or altLabel\n",
    "  ?country rdfs:label|skos:altLabel ?text;\n",
    "           wdt:P31 ?class;\n",
    "           wdt:P31 ?countryType.\n",
    "  # Only include the specified instance types in results\n",
    "  FILTER(?countryType IN (wd:Q6256, wd:Q3024240, wd:Q3624078)).\n",
    "  # Include dates if available\n",
    "  OPTIONAL {{?country wdt:P571 ?startDate.}}\n",
    "  OPTIONAL {{?country wdt:P576 ?endDate.}}\n",
    "  # include geocoords if available\n",
    "  OPTIONAL {{?country p:P625/psv:P625 [wikibase:geoLatitude ?lat; wikibase:geoLongitude ?lon].}}\n",
    "  SERVICE wikibase:label {{\n",
    "    bd:serviceParam wikibase:language \"en\" .\n",
    "  }}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "def chunker(seq, size):\n",
    "    \"\"\"\n",
    "    Split an iterable into smaller chunks for batched processing.\n",
    "    \"\"\"\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "ent_list = ents[\"label\"].to_list()\n",
    "\n",
    "# We'll save processed countries in case we have to restart\n",
    "countries_processed = Path(\"countries_processed.txt\").read_text().split(\"\\n\")\n",
    "\n",
    "with tqdm(total=len(ent_list)) as pbar:\n",
    "    # We can give the WD Sparql querry multiple values,\n",
    "    # so we'll split the list of coutnries up into batches\n",
    "    for chunk in chunker(ent_list, 100):\n",
    "        # Make sure each place name is a string\n",
    "        chunk = [str(e) for e in chunk]\n",
    "        # Submit multiple values in one SPARQL query for efficiency\n",
    "        # Also filters out values containing non-alphabetical characters (except for spaces and hyphens)\n",
    "        query_vals  = \" \".join([f'\"{re.sub(r\"^the \", \"\", e)}\"@en' for e in chunk if e.replace(\" \", \"\").replace(\"-\", \"\").isalpha() and e not in countries_processed])\n",
    "        if query_vals:\n",
    "            # Format the Sparql query\n",
    "            query = query_template.format(query_vals)\n",
    "            # print(query)\n",
    "            # Get the data!\n",
    "            sparql.setQuery(query)\n",
    "            sparql.setReturnFormat(JSON)\n",
    "            results = sparql.query().convert()\n",
    "            df_country = df_clean(results)\n",
    "            # If we've found some matches save them to an ndjson file\n",
    "            if not df_country.empty:\n",
    "                #print(df_country.iloc[0])\n",
    "                #dfs.append(df_country)\n",
    "                countries = df_country.to_dict(orient=\"records\")\n",
    "                for country in countries:\n",
    "                    with Path(\"countries.ndjson\").open(\"a\") as countries_file:\n",
    "                        countries_file.write(f\"{json.dumps(country)}\\n\")\n",
    "            # Keep track of the values we've processed\n",
    "            countries_processed.extend(chunk)\n",
    "            with Path(\"countries_processed.txt\").open(\"a\") as countries_processed_file:\n",
    "                processed = \"\\n\".join(chunk)\n",
    "                countries_processed_file.write(f\"{processed}\\n\")\n",
    "            time.sleep(1)\n",
    "        pbar.update(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7dd77e-a62d-4818-ab62-6a9629d95e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
