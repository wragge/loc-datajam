{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881d6ed3-3e59-4970-b27c-9051a6936b99",
   "metadata": {},
   "source": [
    "# Extracting place names using Spacy and Named Entity Recognition\n",
    "\n",
    "This works through all the text files extracting place names using Named Entity Recognition. The book id and place name are added to the `spacy_ner.txt` file for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "323fecb5-ba97-4e1a-b907-f921193d5345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b426429-b5fc-48df-b514-54f1f971436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('/media/tim/workingData/loc/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bed313c-8edf-4a43-a14f-3bf9574d6d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like this is going to take days to run..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994aa24a-9b92-4227-a133-2b79940aec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Path(\"spacy_ner.txt\").unlink(missing_ok=True)\n",
    "# for text_file in list(itertools.islice(output_path.glob(\"*.txt\"), 50)):\n",
    "processed = Path(\"spacy_processed.txt\").read_text().split(\"\\n\")\n",
    "# This sets the maximum number of chars Spacy will accept\n",
    "# This value is bigger than the default, but not too big or there'll be memory probs\n",
    "# I split bigger texts into chunks lower down...\n",
    "nlp.max_length = 1600000\n",
    "for text_file in tqdm(output_path.glob(\"*.txt\")):\n",
    "    # Keep track of what's been processed in case I need to restart\n",
    "    if text_file.name not in processed:\n",
    "        places = []\n",
    "        text_id = text_file.stem\n",
    "        text = text_file.read_text()\n",
    "        # If the text files are too big there are memory problems and the kernel dies\n",
    "        # So split up big files into paragraph-ish blocks\n",
    "        if len(text) < 1500000:\n",
    "            texts = [text]\n",
    "        else:\n",
    "            texts = text.split(\"\\n\\n\")\n",
    "        for block in texts:\n",
    "            if block.strip():\n",
    "                try:\n",
    "                    doc = nlp(block)\n",
    "                # Blocks too large for Spacy will throw a Value Error\n",
    "                # This is probably because they're undecoded byte string strings\n",
    "                # We'll just record them for now\n",
    "                except ValueError:\n",
    "                    print(text_id)\n",
    "                else:\n",
    "                    # Get place entities\n",
    "                    places.extend([e.text.strip().replace('\\n', '') for e in doc.ents if e.label_ == \"GPE\"])\n",
    "        if places:\n",
    "            # Remove duplicates\n",
    "            ents = list(set(places))\n",
    "            with Path(\"spacy_ner.txt\").open(\"a\") as results_file:\n",
    "                # Just saving the place name and the book id for now\n",
    "                for ent in ents:\n",
    "                    results_file.write(f\"{text_id}\\t{ent}\\n\")\n",
    "        # Update the list of processed files\n",
    "        processed.append(text_file.name)\n",
    "        with Path(\"spacy_processed.txt\").open(\"a\") as processed_file:\n",
    "            processed_file.write(f\"{text_file.name}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba90a42a-0f8b-42bf-aaad-0e4e72d7c42e",
   "metadata": {},
   "source": [
    "Encoding errors:\n",
    "\n",
    "- 09011037.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55307cae-d368-4fb2-a778-93837a287037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
